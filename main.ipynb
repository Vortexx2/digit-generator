{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = T.Compose([\n",
    "  T.ToTensor(),\n",
    "  T.Normalize((0.5, ), (0.5, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_transforms)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "linear_model_path = \"models/lin-gan.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(Y, mean=0.5, std=0.5):\n",
    "  \"\"\"Inverse the normalisation operation. The default values for mean and std are the values used in this notebook\"\"\"\n",
    "  output = std * Y + mean\n",
    "  return output.clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_image(img, label=None, cmap='gray'):\n",
    "  img = img.squeeze(0)\n",
    "  plt.tick_params(left=False, bottom=True, labelleft=False, labelbottom=False)\n",
    "\n",
    "  if label is not None:\n",
    "    plt.title(\"Target digit: \" + str(label))\n",
    "  plt.imshow(img, cmap=cmap)\n",
    "\n",
    "\n",
    "plot_image(denorm(train_data[0][0]), train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 469\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_dataloader(dloader):\n",
    "  for images, labels in train_loader:\n",
    "    plot_image(images[0].numpy(), labels[0].item())\n",
    "\n",
    "    break\n",
    "\n",
    "check_dataloader(train_loader)\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_small_loader(large_loader, num_batches):\n",
    "#   \"\"\"Creates a small loader, it will have `num_batches` batches with size `batch_size`\"\"\"\n",
    "#   small_loader = []\n",
    "\n",
    "#   for i, xy_pair in enumerate(large_loader):\n",
    "#     if (i == num_batches): break\n",
    "\n",
    "#     small_loader.append(xy_pair)\n",
    "\n",
    "#   return small_loader\n",
    "\n",
    "# train_loader = create_small_loader(train_loader, 2)\n",
    "# len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the GAN\n",
    "\n",
    "##### Desigining the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "  def __init__(self, image_size, hidden_size):\n",
    "    super(Discriminator, self).__init__()\n",
    "\n",
    "    self.image_size, self.hidden_size = image_size, hidden_size\n",
    "\n",
    "    self.lin1 = nn.Linear(image_size, hidden_size)\n",
    "    self.lrelu = nn.LeakyReLU(0.2)\n",
    "    self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "    self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.lin3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    \n",
    "  def forward(self, X):\n",
    "    # X = self.bn1(self.lrelu(self.lin1(X)))\n",
    "    # X = self.bn1(self.lrelu(self.lin2(X)))\n",
    "    X = self.lrelu(self.lin1(X))\n",
    "    X = self.lrelu(self.lin2(X))\n",
    "    return torch.sigmoid(self.lin3(X))\n",
    "\n",
    "  def __repr__(self) -> str:\n",
    "    return f\"Linear({self.image_size}, {self.hidden_size}) -> LeakyReLU(0.02) ->\\nLinear({self.hidden_size}, {self.hidden_size}) -> LeakyReLU(0.02) ->\\nLinear({self.hidden_size}, 1) -> Sigmoid()\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(784, 256) -> LeakyReLU(0.02) ->\n",
       "Linear(256, 256) -> LeakyReLU(0.02) ->\n",
       "Linear(256, 1) -> Sigmoid()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size, hidden_size = 784, 256\n",
    "disc = Discriminator(image_size, hidden_size)\n",
    "disc.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Designing the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "  def __init__(self, latent_size, hidden_size, image_size):\n",
    "    super(Generator, self).__init__()\n",
    "    self.lin1 = nn.Linear(latent_size, hidden_size)\n",
    "    self.lrelu = nn.ReLU()\n",
    "\n",
    "    self.lin2 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.lin3 = nn.Linear(hidden_size, image_size)\n",
    "\n",
    "\n",
    "  def forward(self, X):\n",
    "    X = self.lrelu(self.lin1(X))\n",
    "    X = self.lrelu(self.lin2(X))\n",
    "    return torch.tanh(self.lin3(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (lin1): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (lrelu): ReLU()\n",
       "  (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (lin3): Linear(in_features=256, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_size = 64\n",
    "gen = Generator(latent_size, hidden_size, image_size)\n",
    "gen.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing out the generator\n",
    "y = gen(torch.randn((1, latent_size), device=device))\n",
    "plot_image(denorm( y.reshape(1, 28, 28)).detach().cpu().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad(optims):\n",
    "  for optim in optims:\n",
    "    optims[optim].zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_binary(outputs, target_class):\n",
    "  \"\"\"Returns num_correct\"\"\"\n",
    "  len_outputs = outputs.size(0)\n",
    "  num_correct = (torch.round(outputs) == target_class).sum()\n",
    "  return num_correct.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5179],\n",
       "         [0.9062],\n",
       "         [0.6121]]),\n",
       " 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((3, 1))\n",
    "a, get_accuracy_binary(a, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(images, disc, gen, optimizers, criterion):\n",
    "  \"\"\"Returns the following for each minibatch: `(loss, real_score, fake_score)`\"\"\"\n",
    "\n",
    "  # batch_size is redefined because len of images might be redefined somewhere else\n",
    "  batch_size = len(images)\n",
    "\n",
    "  real_labels = torch.ones((batch_size, 1), device=device)\n",
    "  fake_labels = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "  # train on real data, discriminator should aim to predict 1\n",
    "  outputs = disc(images)\n",
    "  d_real = criterion(outputs, real_labels)\n",
    "  # we set target class to 1 below, because discriminator's accuracy on real images should be based on 1\n",
    "  real_score = get_accuracy_binary(outputs, 1)\n",
    "\n",
    "  # train on fake data, discriminator should aim to predict 0\n",
    "  Z = torch.randn((batch_size, latent_size), device=device)\n",
    "  fake_images = gen(Z)\n",
    "\n",
    "  outputs = disc(fake_images)\n",
    "  # we set target class to 0 below, because discriminator's accuracy on fake images should be based on 0\n",
    "  d_fake = criterion(outputs, fake_labels)\n",
    "  fake_score = get_accuracy_binary(outputs, 0)\n",
    "\n",
    "  d_loss = d_real + d_fake\n",
    "\n",
    "  reset_grad(optimizers)\n",
    "  d_loss.backward()\n",
    "  nn.utils.clip_grad_norm_(disc.parameters(), 1)\n",
    "\n",
    "  optimizers[\"disc\"].step()\n",
    "\n",
    "  return d_loss, real_score, fake_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(disc, gen, optimizers, loss):\n",
    "  \"\"\"Returns the following for 1 minibatch: `(loss, fake_images)`. This loss is the loss attributed to the amount of images that the generator produced that got classified as fake. This will aim to improve the generator.\"\"\"\n",
    "  real_labels = torch.ones((batch_size, 1), device=device)\n",
    "\n",
    "  Z = torch.randn((batch_size, latent_size), device=device)\n",
    "  fake_images = gen(Z)\n",
    "\n",
    "  disc_preds = disc(fake_images)\n",
    "\n",
    "  # fake_score = get_accuracy_binary(disc_preds, 1)\n",
    "\n",
    "  # generator has to try and fool the discriminator\n",
    "  # try and make the discriminator predict 1 for actually fake images\n",
    "  d_loss = loss(disc_preds, real_labels)\n",
    "\n",
    "  reset_grad(optimizers)\n",
    "  d_loss.backward()\n",
    "  nn.utils.clip_grad_norm_(disc.parameters(), 1)\n",
    "  nn.utils.clip_grad_norm_(gen.parameters(), 1)\n",
    "  \n",
    "  optimizers['gen'].step()\n",
    "\n",
    "  return d_loss, fake_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilites for visualisation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_samples_dir, fake_samples_dir = 'samples/real', 'samples/fake'\n",
    "\n",
    "for dir in [real_samples_dir, fake_samples_dir]:\n",
    "  os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "n_rows, n_cols = 8, 8\n",
    "\n",
    "\n",
    "def save_real_images(loader):\n",
    "\n",
    "  real_grid_path = os.path.join(real_samples_dir, 'real_grid.png')\n",
    "\n",
    "  # if real image grid exists, don't make it again\n",
    "  if os.path.exists(real_grid_path):\n",
    "    return\n",
    "\n",
    "  # we will save a grid of real images\n",
    "  for images, labels in loader:\n",
    "    images = denorm(images)\n",
    "    grid_image = make_grid(images, n_rows).permute(1, 2, 0)\n",
    "    plot_image(grid_image, \"Grid of real images\")\n",
    "    print(\"Saving above real grid of images\")\n",
    "    save_image(images, real_grid_path, n_rows=n_rows)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_latent_vector = torch.randn((batch_size, latent_size), device=device)\n",
    "\n",
    "def save_fake_images(index):\n",
    "  gen_images = gen(sample_latent_vector)\n",
    "\n",
    "  target_shape = (sample_latent_vector.size(0), 1, 28, 28)\n",
    "  gen_images = denorm(gen_images).reshape(target_shape)\n",
    "  fake_grid_path = os.path.join(fake_samples_dir, f\"fake_{index:04d}.png\")\n",
    "  save_image(gen_images, fake_grid_path, n_rows=n_rows)\n",
    "\n",
    "save_fake_images(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the entire network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "\n",
    "optimizers = {\n",
    "  \"disc\": torch.optim.Adam(disc.parameters(), lr=lr),\n",
    "  \"gen\": torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187 | 600]: \n",
      "\t d_loss: 1.5834379196166992, g_loss: 1.05126953125, D(X): 49, D(G(z)): 51\n",
      "Epoch [188 | 600]: \n",
      "\t d_loss: 2.2828643321990967, g_loss: 0.5175380706787109, D(X): 59, D(G(z)): 16\n",
      "Epoch [189 | 600]: \n",
      "\t d_loss: 2.07662296295166, g_loss: 0.48934727907180786, D(X): 67, D(G(z)): 18\n",
      "Saving the fake images for the epoch 189\n",
      "Epoch [190 | 600]: \n",
      "\t d_loss: 0.8039531707763672, g_loss: 2.006746292114258, D(X): 71, D(G(z)): 87\n",
      "Epoch [191 | 600]: \n",
      "\t d_loss: 1.0864113569259644, g_loss: 1.4285824298858643, D(X): 71, D(G(z)): 64\n",
      "Epoch [192 | 600]: \n",
      "\t d_loss: 1.5496337413787842, g_loss: 0.8370823264122009, D(X): 73, D(G(z)): 37\n",
      "Saving the fake images for the epoch 192\n",
      "Epoch [193 | 600]: \n",
      "\t d_loss: 1.8668965101242065, g_loss: 0.6383513808250427, D(X): 60, D(G(z)): 30\n",
      "Epoch [194 | 600]: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19368/2181867440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19368/2181867440.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(disc, gen, train_loader, optimizers, loss, num_epochs, train_if_exists)\u001b[0m\n\u001b[0;32m     29\u001b[0m       \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m       \u001b[0md_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m       \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19368/3795095837.py\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[1;34m(images, disc, gen, optimizers, criterion)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[0mreset_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m   \u001b[0md_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m   \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramFiles\\anaconda\\envs\\fastapi-ml\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32md:\\ProgramFiles\\anaconda\\envs\\fastapi-ml\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "def init_weights(m):\n",
    "  if isinstance(m, nn.Linear):\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "    m.bias.data.fill_(0)\n",
    "\n",
    "def train_network(disc, gen, train_loader, optimizers, loss, num_epochs, train_if_exists=False):\n",
    "\n",
    "  disc.apply(init_weights)\n",
    "  \n",
    "  starting_epoch = 0\n",
    "\n",
    "  if os.path.exists(linear_model_path):\n",
    "    checkpoint = torch.load(linear_model_path)\n",
    "    disc.load_state_dict(checkpoint[\"disc_state_dict\"])\n",
    "    gen.load_state_dict(checkpoint[\"gen_state_dict\"])\n",
    "    loss = checkpoint[\"criterion\"]\n",
    "    starting_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "  d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
    "\n",
    "  for epoch in range(starting_epoch, num_epochs ):\n",
    "\n",
    "    print(f\"Epoch [{epoch} | {num_epochs}]: \")\n",
    "\n",
    "    for i, ( images, labels ) in enumerate( train_loader ):\n",
    "\n",
    "      images = images.reshape(images.size(0), -1).to(device)\n",
    "\n",
    "      d_loss, real_score, fake_score = train_discriminator(images, disc, gen, optimizers, loss)\n",
    "      g_loss, fake_images = train_generator(disc, gen, optimizers, loss)\n",
    "\n",
    "    print(f\"\\t d_loss: {d_loss}, g_loss: {g_loss}, D(X): {real_score}, D(G(z)): {fake_score}\")\n",
    "\n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "    real_scores.append(real_score)\n",
    "    fake_scores.append(fake_score)\n",
    "    \n",
    "    if epoch % 3 == 0:\n",
    "      print(f\"Saving the fake images for the epoch {epoch}\")\n",
    "      save_fake_images(epoch)\n",
    "\n",
    "  \n",
    "  return d_losses, g_losses, real_scores, fake_scores\n",
    "\n",
    "\n",
    "train_network(disc, gen, train_loader, optimizers, criterion, 600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = torch.randn((1, latent_size), device=device)\n",
    "plot_image(gen(Z).reshape(28, 28).detach().cpu())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "  \"epoch\": 187,\n",
    "  \"disc_state_dict\": disc.state_dict(),\n",
    "  \"gen_state_dict\": gen.state_dict(),\n",
    "  \"criterion\": criterion\n",
    "}, linear_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a72f2fb76a61cd37ad6891cc8d4df39cb21bbe70362a60424286c2696b35476d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
